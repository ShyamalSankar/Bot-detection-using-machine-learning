{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0811ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import gif2numpy\n",
    "\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "import splitfolders\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.metrics import Accuracy, Precision, Recall\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "import re\n",
    "\n",
    "from datetime import date,datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f586e9",
   "metadata": {},
   "source": [
    "# Processing and loading metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4097b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting relevant rows\n",
    "meta_data = pd.read_csv('final_combined_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb613ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the processing functions previously defined\n",
    "def url(df):\n",
    "    df[\"has_url\"] = ~df[\"url\"].isna()\n",
    "    return df\n",
    "\n",
    "def username(df):\n",
    "    special_char = re.compile('[@_!#$%^&*()<>?/\\|}{~:]')\n",
    "    df[\"un_no_of_char\"] = df[\"username\"].apply(lambda x: len(str(x)))\n",
    "    df[\"un_special_char\"] = df[\"username\"].apply(lambda x: special_char.search(str(x)) != None)\n",
    "    return df\n",
    "\n",
    "def name(df):\n",
    "    special_char = re.compile('[@_!#$%^&*()<>?/\\|}{~:]')\n",
    "    df[\"name_no_of_char\"] = df[\"name\"].apply(lambda x: len(str(x)))\n",
    "    df[\"name_special_char\"] = df[\"name\"].apply(lambda x: special_char.search(str(x)) != None)\n",
    "    return df\n",
    "\n",
    "def description(df):\n",
    "    user_tags = r'\\B@\\w*[a-zA-Z]*\\w*'\n",
    "    hashtags = r'\\B#\\w*[a-zA-Z]+\\w*'\n",
    "    links = r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}[-a-zA-Z0-9()@:%_+.~#?&/=]*)'\n",
    "    df[\"des_no_of_usertags\"] = df[\"description\"].apply(lambda x: len(re.findall(user_tags, str(x)))) #str(x).count('@'))\n",
    "    df[\"des_no_of_hashtags\"] = df[\"description\"].apply(lambda x: len(re.findall(hashtags, str(x)))) #str(x).count('#'))\n",
    "    df[\"des_external_links\"] = df[\"description\"].apply(lambda x: re.findall(links, str(x)) != [])\n",
    "    df[\"has_description\"] = ~df[\"description\"].isna() \n",
    "    return df\n",
    "\n",
    "def location(df):\n",
    "    df[\"location\"] = ~df[\"location\"].isna() # false = location is NaN; true = has location\n",
    "    return df\n",
    "  \n",
    "def time(df):\n",
    "    # df[\"created_time\"] = df[\"created_at\"].apply(lambda x : datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%f%z').date())\n",
    "    # d1 = date(2022, 10, 8) # date we extracted these data \n",
    "    df[\"account_age_in_days\"] = df[\"created_at\"].apply(lambda x : (date(2022, 10, 8) - datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%f%z').date()).days)\n",
    "    df[\"average_tweets_per_day\"] = df[\"tweet_count\"]/df[\"account_age_in_days\"]\n",
    "    return df\n",
    "\n",
    "def follow_count(df):\n",
    "    df[\"followers_following_count\"] = df[\"followers_count\"] * df[\"following_count\"]\n",
    "    return df\n",
    "\n",
    "def account_type(df):\n",
    "    df[\"isBot\"] = df[\"account_type\"].apply(lambda x : 1 if x == 'bot' else 0)\n",
    "    return df\n",
    "\n",
    "def convert_PV(variable):\n",
    "    if variable == 'True':\n",
    "        return True\n",
    "    if variable == 'False':\n",
    "        return False\n",
    "    if variable == '0.0':\n",
    "        return False\n",
    "    if variable == '1.0':\n",
    "        return True\n",
    "    return variable\n",
    "\n",
    "def convert_TF(variable):\n",
    "    var = 1 if variable == True else 0\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b646fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = account_type(meta_data)\n",
    "meta_data = username(meta_data)\n",
    "meta_data = name(meta_data)\n",
    "meta_data = description(meta_data)\n",
    "meta_data = location(meta_data)\n",
    "meta_data = url(meta_data)\n",
    "meta_data = time(meta_data)\n",
    "meta_data = follow_count(meta_data)\n",
    "\n",
    "pv_var = [\"verified\", \"protected\"]\n",
    "\n",
    "for var in pv_var:\n",
    "    meta_data[var] = meta_data[var].apply(convert_PV)\n",
    "\n",
    "boolean_var = [\"verified\", \"location\", \"un_special_char\", \n",
    "               \"name_special_char\", \"des_external_links\", \n",
    "               \"has_description\", \"protected\", \n",
    "               \"has_url\", \"has_profile_image\"]\n",
    "\n",
    "for var in boolean_var:\n",
    "    meta_data[var] = meta_data[var].apply(convert_TF)\n",
    "    \n",
    "int_var = [\"followers_count\", \"following_count\", \"tweet_count\", \"listed_count\"]\n",
    "\n",
    "for var in int_var:\n",
    "    meta_data[var] = meta_data[var].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66e5dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_metadata = meta_data.drop(columns=[\"Unnamed: 0\", \"url\", \"created_at\", \"name\", \"username\", \"description\", \"profile_image_url\", \"account_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e11e0f",
   "metadata": {},
   "source": [
    "# Loading the image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd644ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets \n",
    "# splitfolders.ratio(\"./pictures2\", output=\"images_split\", ratio=(.8, .1, .1), group_prefix=None, move=False) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d745043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 200\n",
    "IMG_HEIGHT = 200\n",
    "\n",
    "def create_dataset(img_folder, bot=True):\n",
    "    img_data_array = []\n",
    "    class_name = []\n",
    "    image_paths = []\n",
    "    \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        image_path = os.path.join(img_folder, dir1)\n",
    "        image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
    "        image_paths.append(image_path)\n",
    "        try:\n",
    "            image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n",
    "        except:\n",
    "            image = gif2numpy.convert(image_path)[0][0]\n",
    "            image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255 \n",
    "        img_data_array.append(image)\n",
    "        if bot:\n",
    "            class_name.append([1])\n",
    "        else: \n",
    "            class_name.append([0])\n",
    "    return img_data_array, class_name, image_paths\n",
    "\n",
    "# extract the image array and class name\n",
    "bot_train, class_name_bot, bot_image_paths = create_dataset('./images_split/train/1_bot')\n",
    "human_train, class_name_human, human_image_paths = create_dataset('./images_split/train/0_human', False)\n",
    "\n",
    "bot_test, class_name_bot_test, bot_test_paths = create_dataset('./images_split/test/1_bot')\n",
    "human_test, class_name_human_test, human_test_paths = create_dataset('./images_split/test/0_human', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d8cb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n",
      "3300\n",
      "4880\n",
      "4880\n"
     ]
    }
   ],
   "source": [
    "print(len(bot_train))\n",
    "print(len(class_name_bot))\n",
    "print(len(human_train))\n",
    "print(len(class_name_human))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6641b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell, we define functions to process the file names and convert them to ids in order to extract the relevant\n",
    "#rows from the metadata set.\n",
    "def bot_name_process(text):\n",
    "    text = text.replace(\"./images_split/train/1_bot\\\\\", \"\")\n",
    "    text = text.replace(\".jpeg\", \"\")\n",
    "    text = text.replace(\".png\", \"\")\n",
    "    text = text.replace(\".jpg\", \"\")\n",
    "    text = text.replace(\".gif\", \"\")\n",
    "    \n",
    "    text_lst = text.split(\".\")\n",
    "    text = text_lst[0]\n",
    "    \n",
    "    id_account = int(text)\n",
    "    \n",
    "    \n",
    "    return id_account\n",
    "\n",
    "\n",
    "def human_name_process(text):\n",
    "    text = text.replace(\"./images_split/train/0_human\\\\\", \"\")\n",
    "    text = text.replace(\".jpeg\", \"\")\n",
    "    text = text.replace(\".png\", \"\")\n",
    "    text = text.replace(\".jpg\", \"\")\n",
    "    text = text.replace(\".gif\", \"\")\n",
    "    \n",
    "    text_lst = text.split(\".\")\n",
    "    text = text_lst[0]\n",
    "    \n",
    "    id_account = int(text)\n",
    "    \n",
    "    \n",
    "    return id_account\n",
    "\n",
    "def val_human_name_process(text):\n",
    "    text = text.replace(\"./images_split\\\\val\\\\0_human\\\\\", \"\")\n",
    "    text = text.replace(\".jpeg\", \"\")\n",
    "    text = text.replace(\".png\", \"\")\n",
    "    text = text.replace(\".jpg\", \"\")\n",
    "    text = text.replace(\".gif\", \"\")\n",
    "    \n",
    "    text_lst = text.split(\".\")\n",
    "    text = text_lst[0]\n",
    "    \n",
    "    id_account = int(text)\n",
    "    \n",
    "    \n",
    "    return id_account\n",
    "\n",
    "def val_bot_name_process(text):\n",
    "    text = text.replace(\"./images_split\\\\val\\\\1_bot\\\\\", \"\")\n",
    "    text = text.replace(\".jpeg\", \"\")\n",
    "    text = text.replace(\".png\", \"\")\n",
    "    text = text.replace(\".jpg\", \"\")\n",
    "    text = text.replace(\".gif\", \"\")\n",
    "    \n",
    "    text_lst = text.split(\".\")\n",
    "    text = text_lst[0]\n",
    "    \n",
    "    id_account = int(text)\n",
    "\n",
    "    \n",
    "\n",
    "def test_bot_name_process(text):\n",
    "    text = text.replace(\"./images_split/test/1_bot\\\\\", \"\")\n",
    "    text = text.replace(\".jpeg\", \"\")\n",
    "    text = text.replace(\".png\", \"\")\n",
    "    text = text.replace(\".jpg\", \"\")\n",
    "    text = text.replace(\".gif\", \"\")\n",
    "    \n",
    "    text_lst = text.split(\".\")\n",
    "    text = text_lst[0]\n",
    "    \n",
    "    id_account = int(text)\n",
    "    \n",
    "    \n",
    "    return id_account\n",
    "\n",
    "\n",
    "def test_human_name_process(text):\n",
    "    text = text.replace(\"./images_split/test/0_human\\\\\", \"\")\n",
    "    text = text.replace(\".jpeg\", \"\")\n",
    "    text = text.replace(\".png\", \"\")\n",
    "    text = text.replace(\".jpg\", \"\")\n",
    "    text = text.replace(\".gif\", \"\")\n",
    "    \n",
    "    text_lst = text.split(\".\")\n",
    "    text = text_lst[0]\n",
    "    \n",
    "    id_account = int(text)\n",
    "    \n",
    "    \n",
    "    return id_account\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d19647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the relevant ids to filter the metadata dataframe later\n",
    "\n",
    "#training set rows\n",
    "training_bot_ids = list(map(bot_name_process, bot_image_paths))\n",
    "\n",
    "training_human_ids = list(map(human_name_process, human_image_paths))\n",
    "\n",
    "test_bot_ids = list(map(test_bot_name_process, bot_test_paths))\n",
    "\n",
    "test_human_ids = list(map(test_human_name_process, human_test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a6021e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#getting the images in array form\n",
    "bot_train = np.array(bot_train, dtype=np.float32)\n",
    "human_train = np.array(human_train, dtype=np.float32)\n",
    "train_images = np.concatenate((bot_train, human_train), dtype=np.float32)\n",
    "train_labels = np.array(class_name_bot+class_name_human, np.float32)\n",
    "\n",
    "bot_test = np.array(bot_test, dtype=np.float32)\n",
    "human_test = np.array(human_test, dtype=np.float32)\n",
    "test_images = np.concatenate((bot_test, human_test), dtype=np.float32)\n",
    "test_labels = np.array(class_name_bot_test+class_name_human_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94863e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4880, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(human_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b5d0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8180, 200, 200, 3)\n",
      "(8180, 1)\n",
      "(1024, 200, 200, 3)\n",
      "(1024, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db67bc5",
   "metadata": {},
   "source": [
    "# Extracting relevant rows of metadata \n",
    "In this section, we shall extract the relevant rows of the metadata and preprocess them for the multi channel neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0f4ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting relevant rows of the metadata\n",
    "\n",
    "#training data\n",
    "training_metadata = processed_metadata[processed_metadata.id.isin(training_bot_ids + training_human_ids)] \n",
    "\n",
    "#testing data\n",
    "testing_metadata = processed_metadata[processed_metadata.id.isin(test_bot_ids + test_human_ids)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "480de32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensuring that the order in both training and testing match the order in the image array (ie ensuring that the profile image\n",
    "#matches to the corresponding metadata) For this, we will have to assign the ids to a dictionary that the value corresponds to\n",
    "#its index\n",
    "\n",
    "training_ids = training_bot_ids + training_human_ids\n",
    "\n",
    "ordered_dict_train = {k:v for k,v in enumerate(training_ids)}\n",
    "\n",
    "sorting_dict_train = {v:k for k,v in enumerate(training_ids)}\n",
    "\n",
    "testing_ids = test_bot_ids + test_human_ids\n",
    "\n",
    "ordered_dict_test = {k:v for k,v in enumerate(testing_ids)}\n",
    "\n",
    "sorting_dict_test = {v:k for k,v in enumerate(testing_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f497711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordering the respective dataframes in the correct order\n",
    "\n",
    "training_metadata.sort_values(by = 'id', key = lambda x: x.map(sorting_dict_train), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d213601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_metadata.sort_values(by = 'id', key = lambda x: x.map(sorting_dict_test), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f365f7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>protected</th>\n",
       "      <th>verified</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>has_profile_image</th>\n",
       "      <th>isBot</th>\n",
       "      <th>...</th>\n",
       "      <th>name_no_of_char</th>\n",
       "      <th>name_special_char</th>\n",
       "      <th>des_no_of_usertags</th>\n",
       "      <th>des_no_of_hashtags</th>\n",
       "      <th>des_external_links</th>\n",
       "      <th>has_description</th>\n",
       "      <th>has_url</th>\n",
       "      <th>account_age_in_days</th>\n",
       "      <th>average_tweets_per_day</th>\n",
       "      <th>followers_following_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6386</th>\n",
       "      <td>1021573561</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>159</td>\n",
       "      <td>1577</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3580</td>\n",
       "      <td>0.440503</td>\n",
       "      <td>28143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730</th>\n",
       "      <td>1022420287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17742</td>\n",
       "      <td>11883</td>\n",
       "      <td>5544</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3580</td>\n",
       "      <td>1.548603</td>\n",
       "      <td>210828186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16034</th>\n",
       "      <td>1024955420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>222</td>\n",
       "      <td>7261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3579</td>\n",
       "      <td>2.028779</td>\n",
       "      <td>11544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>1070386470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7796</td>\n",
       "      <td>1</td>\n",
       "      <td>12028</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3560</td>\n",
       "      <td>3.378652</td>\n",
       "      <td>7796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18089</th>\n",
       "      <td>1071014605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4325</td>\n",
       "      <td>4812</td>\n",
       "      <td>4176</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3560</td>\n",
       "      <td>1.173034</td>\n",
       "      <td>20811900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>9895182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>519</td>\n",
       "      <td>127</td>\n",
       "      <td>10674</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5454</td>\n",
       "      <td>1.957096</td>\n",
       "      <td>65913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18708</th>\n",
       "      <td>9981032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>198</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5451</td>\n",
       "      <td>0.370024</td>\n",
       "      <td>36234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>9982862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>394</td>\n",
       "      <td>627</td>\n",
       "      <td>12453</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5450</td>\n",
       "      <td>2.284954</td>\n",
       "      <td>247038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>9988572</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1106</td>\n",
       "      <td>1306</td>\n",
       "      <td>10093</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5450</td>\n",
       "      <td>1.851927</td>\n",
       "      <td>1444436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>9991572</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>318</td>\n",
       "      <td>752</td>\n",
       "      <td>59238</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5450</td>\n",
       "      <td>10.869358</td>\n",
       "      <td>239136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8180 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  protected  verified  location  followers_count  \\\n",
       "6386   1021573561          0         0         1              177   \n",
       "7730   1022420287          0         0         0            17742   \n",
       "16034  1024955420          0         0         0               52   \n",
       "3985   1070386470          0         0         1             7796   \n",
       "18089  1071014605          0         0         1             4325   \n",
       "...           ...        ...       ...       ...              ...   \n",
       "4416      9895182          0         0         1              519   \n",
       "18708     9981032          0         0         1              183   \n",
       "2347      9982862          0         0         1              394   \n",
       "919       9988572          1         0         1             1106   \n",
       "5890      9991572          1         0         1              318   \n",
       "\n",
       "       following_count  tweet_count  listed_count  has_profile_image  isBot  \\\n",
       "6386               159         1577             4                  1      1   \n",
       "7730             11883         5544            89                  1      1   \n",
       "16034              222         7261             1                  1      1   \n",
       "3985                 1        12028            27                  1      1   \n",
       "18089             4812         4176             7                  1      1   \n",
       "...                ...          ...           ...                ...    ...   \n",
       "4416               127        10674            10                  1      0   \n",
       "18708              198         2017             2                  1      0   \n",
       "2347               627        12453            10                  1      0   \n",
       "919               1306        10093            27                  1      0   \n",
       "5890               752        59238            21                  1      0   \n",
       "\n",
       "       ...  name_no_of_char  name_special_char  des_no_of_usertags  \\\n",
       "6386   ...               16                  0                   0   \n",
       "7730   ...               18                  0                   0   \n",
       "16034  ...               17                  0                   0   \n",
       "3985   ...               18                  0                   0   \n",
       "18089  ...               14                  0                   0   \n",
       "...    ...              ...                ...                 ...   \n",
       "4416   ...               12                  0                   1   \n",
       "18708  ...               12                  0                   0   \n",
       "2347   ...               13                  0                   0   \n",
       "919    ...               14                  0                   0   \n",
       "5890   ...                3                  0                   0   \n",
       "\n",
       "       des_no_of_hashtags  des_external_links  has_description  has_url  \\\n",
       "6386                    0                   0                1        1   \n",
       "7730                    0                   0                1        0   \n",
       "16034                   0                   0                0        0   \n",
       "3985                    0                   0                1        0   \n",
       "18089                   0                   0                1        0   \n",
       "...                   ...                 ...              ...      ...   \n",
       "4416                    2                   0                1        1   \n",
       "18708                   0                   0                1        1   \n",
       "2347                    0                   0                1        1   \n",
       "919                     0                   0                1        1   \n",
       "5890                    0                   0                1        0   \n",
       "\n",
       "       account_age_in_days  average_tweets_per_day  followers_following_count  \n",
       "6386                  3580                0.440503                      28143  \n",
       "7730                  3580                1.548603                  210828186  \n",
       "16034                 3579                2.028779                      11544  \n",
       "3985                  3560                3.378652                       7796  \n",
       "18089                 3560                1.173034                   20811900  \n",
       "...                    ...                     ...                        ...  \n",
       "4416                  5454                1.957096                      65913  \n",
       "18708                 5451                0.370024                      36234  \n",
       "2347                  5450                2.284954                     247038  \n",
       "919                   5450                1.851927                    1444436  \n",
       "5890                  5450               10.869358                     239136  \n",
       "\n",
       "[8180 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing the dataframe\n",
    "training_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07a71d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now drop the id column\n",
    "training_metadata.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5444ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_metadata.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eee610d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numeric_variables = ['followers_count', 'following_count', 'listed_count', 'tweet_count', 'un_no_of_char','name_no_of_char', 'des_no_of_usertags', 'des_no_of_hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd4dda78",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metadata[numeric_variables] = scaler.fit_transform(training_metadata[numeric_variables])\n",
    "\n",
    "testing_metadata[numeric_variables] = scaler.transform(testing_metadata[numeric_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2562a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_metadata.loc[:,training_metadata.columns != 'isBot']\n",
    "y_train = training_metadata[['isBot']]\n",
    "\n",
    "X_test = testing_metadata.loc[:, testing_metadata.columns != 'isBot']\n",
    "y_test = testing_metadata[['isBot']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4c7ddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# import the InceptionV3 model  \n",
    "pre_trained_model = InceptionV3(input_shape = (200, 200, 3), # Shape of our images\n",
    "                                include_top = False, # Leave out the last fully connected layer\n",
    "                                weights = 'imagenet')\n",
    "\n",
    "# freeze layers\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.959):\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6721348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the output layer to 1 dimension\n",
    "flat = layers.Flatten()(pre_trained_model.output)\n",
    "\n",
    "# add a fully connected layer with 2048 hidden units and ReLU activation\n",
    "dense1 = layers.Dense(2048, activation='relu')(flat)\n",
    "\n",
    "# add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "dense2 = layers.Dense(1024, activation='tanh')(dense1)\n",
    "\n",
    "# add a fully connected layer with 256 hidden units and ReLU activation\n",
    "dense3 = layers.Dense(256, activation='relu')(dense2)\n",
    "\n",
    "#add a dense layer which would be concatenated with the metadata information\n",
    "dense4 = layers.Dense(16, activation='relu')(dense3)\n",
    "\n",
    "input_metadata = layers.Input(shape = (20,))\n",
    "\n",
    "combined = layers.concatenate([input_metadata, dense4])\n",
    "\n",
    "#add 2 more dense layers to complete the training\n",
    "dense5 = layers.Dense(128, activation = 'relu')(combined)\n",
    "\n",
    "dense6 = layers.Dense(64, activation = 'relu')(dense5)\n",
    "\n",
    "# add a final sigmoid layer for classification\n",
    "output = layers.Dense(1, activation='sigmoid')(dense6)           \n",
    "\n",
    "model = Model(inputs = [pre_trained_model.input, input_metadata], outputs = [output]) \n",
    "\n",
    "\n",
    "metrics = [\n",
    "    #keras.metrics.Accuracy(name=\"accuracy\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(optimizer = Adam(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc', metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2848e50c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f1fad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Before training our model, we shall shuffle the training data\n",
    "\n",
    "train_images, train_labels, X_train = shuffle(train_images, train_labels, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b73b41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "256/256 - 439s - loss: 45426.6289 - acc: 0.7347 - precision: 0.7592 - recall: 0.5015 - 439s/epoch - 2s/step\n",
      "Epoch 2/20\n",
      "256/256 - 492s - loss: 20732.2578 - acc: 0.7540 - precision: 0.7410 - recall: 0.6000 - 492s/epoch - 2s/step\n",
      "Epoch 3/20\n",
      "256/256 - 502s - loss: 114411.9531 - acc: 0.7446 - precision: 0.7198 - recall: 0.6009 - 502s/epoch - 2s/step\n",
      "Epoch 4/20\n",
      "256/256 - 461s - loss: 206106.8906 - acc: 0.7944 - precision: 0.8759 - recall: 0.5712 - 461s/epoch - 2s/step\n",
      "Epoch 5/20\n",
      "256/256 - 451s - loss: 170057.3281 - acc: 0.8079 - precision: 0.8324 - recall: 0.6561 - 451s/epoch - 2s/step\n",
      "Epoch 6/20\n",
      "256/256 - 435s - loss: 71650.9531 - acc: 0.8782 - precision: 0.8967 - recall: 0.7891 - 435s/epoch - 2s/step\n",
      "Epoch 7/20\n",
      "256/256 - 452s - loss: 234671.2812 - acc: 0.7648 - precision: 0.7034 - recall: 0.7209 - 452s/epoch - 2s/step\n",
      "Epoch 8/20\n",
      "256/256 - 444s - loss: 21496.3945 - acc: 0.8068 - precision: 0.7769 - recall: 0.7312 - 444s/epoch - 2s/step\n",
      "Epoch 9/20\n",
      "256/256 - 448s - loss: 39291.5117 - acc: 0.8065 - precision: 0.7876 - recall: 0.7124 - 448s/epoch - 2s/step\n",
      "Epoch 10/20\n",
      "256/256 - 2296s - loss: 19920.6445 - acc: 0.8159 - precision: 0.7884 - recall: 0.7430 - 2296s/epoch - 9s/step\n",
      "Epoch 11/20\n",
      "256/256 - 446s - loss: 16148.4941 - acc: 0.8155 - precision: 0.7729 - recall: 0.7685 - 446s/epoch - 2s/step\n",
      "Epoch 12/20\n",
      "256/256 - 485s - loss: 41901.8438 - acc: 0.8337 - precision: 0.8268 - recall: 0.7436 - 485s/epoch - 2s/step\n",
      "Epoch 13/20\n",
      "256/256 - 496s - loss: 48417.1719 - acc: 0.8521 - precision: 0.8375 - recall: 0.7858 - 496s/epoch - 2s/step\n",
      "Epoch 14/20\n",
      "256/256 - 451s - loss: 173397.4688 - acc: 0.7925 - precision: 0.7685 - recall: 0.6952 - 451s/epoch - 2s/step\n",
      "Epoch 15/20\n",
      "256/256 - 492s - loss: 22519.7969 - acc: 0.8600 - precision: 0.8308 - recall: 0.8200 - 492s/epoch - 2s/step\n",
      "Epoch 16/20\n",
      "256/256 - 502s - loss: 7203.7080 - acc: 0.8894 - precision: 0.8650 - recall: 0.8600 - 502s/epoch - 2s/step\n",
      "Epoch 17/20\n",
      "256/256 - 499s - loss: 5334.1562 - acc: 0.9045 - precision: 0.8932 - recall: 0.8670 - 499s/epoch - 2s/step\n",
      "Epoch 18/20\n",
      "256/256 - 466s - loss: 9348.7842 - acc: 0.8982 - precision: 0.8927 - recall: 0.8497 - 466s/epoch - 2s/step\n",
      "Epoch 19/20\n",
      "256/256 - 472s - loss: 6637.0786 - acc: 0.9004 - precision: 0.8815 - recall: 0.8700 - 472s/epoch - 2s/step\n",
      "Epoch 20/20\n",
      "256/256 - 463s - loss: 3278.8027 - acc: 0.8576 - precision: 0.8266 - recall: 0.8188 - 463s/epoch - 2s/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            x = [train_images, X_train],\n",
    "            y = train_labels,\n",
    "            #steps_per_epoch = 100,\n",
    "            epochs = 20,\n",
    "            #validation_steps = 50,\n",
    "            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87c475b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 59s 2s/step - loss: 1781.1968 - acc: 0.9492 - precision: 1.0000 - recall: 0.8741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1781.19677734375, 0.94921875, 1.0, 0.8740919828414917]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = [test_images, X_test], y = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e6f57be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 59s 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x = [test_images, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85c60eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = np.where(y_pred > 0.5, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7d5bc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.937046004842615\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       611\n",
      "           1       1.00      0.87      0.93       413\n",
      "\n",
      "    accuracy                           0.95      1024\n",
      "   macro avg       0.96      0.94      0.95      1024\n",
      "weighted avg       0.95      0.95      0.95      1024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred_labels)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_labels)\n",
    "\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

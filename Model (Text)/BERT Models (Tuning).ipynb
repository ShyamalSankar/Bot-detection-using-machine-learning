{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d16bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing of necessary packages\n",
    "import nltk\n",
    "import re\n",
    "import emoji\n",
    "import demoji\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "from numpy import loadtxt, savetxt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D, BatchNormalization, Bidirectional\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#import bayes opt for hyperparameter tuning\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7325d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the dataset\n",
    "df_human = pd.read_csv('human_tweets_processed.csv')\n",
    "df_fake = pd.read_csv('bot_tweets_fake_processed.csv')\n",
    "df_social = pd.read_csv('bot_tweets_social_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e15b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_all = pd.concat([df_human, df_fake, df_social])\n",
    "df_tweets_all = df_tweets_all.reset_index(inplace = False, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140a6921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>isBot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@KyleDavidHall @YouTube YASS  THANKS BABE</td>\n",
       "      <td>__user_mention__ __user_mention__ YASS THANKS ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @AbnInfVet: ...And Then Bloomberg Says He D...</td>\n",
       "      <td>RT __user_mention__ ...And Then Bloomberg Says...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @lgbtqnation: Federal judge considers separ...</td>\n",
       "      <td>RT __user_mention__ Federal judge considers se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @OKFosterWishes: URGENT; Beds needed to get...</td>\n",
       "      <td>RT __user_mention__ URGENT; Beds needed to get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @luke_brooks: N.America and EU! Our EP \"Wou...</td>\n",
       "      <td>RT __user_mention__ N.America and EU! Our EP \"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248177</th>\n",
       "      <td>theawkwardmoment#theawkwardmoment when you sta...</td>\n",
       "      <td>theawkwardmoment#theawkwardmoment when you sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248178</th>\n",
       "      <td>I will have the rest of the site updated when ...</td>\n",
       "      <td>I will have the rest of the site updated when ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248179</th>\n",
       "      <td>RT @EMANSANGELS: Follow @scottstorch and view ...</td>\n",
       "      <td>RT __user_mention__ Follow __user_mention__ an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248180</th>\n",
       "      <td>Stupidity in numbers.  penn state riot</td>\n",
       "      <td>Stupidity in numbers. penn state riot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248181</th>\n",
       "      <td>RT @Srkrokx: Website Rank | Search Engine Opti...</td>\n",
       "      <td>RT __user_mention__ Website Rank | Search Engi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248182 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0               @KyleDavidHall @YouTube YASS  THANKS BABE   \n",
       "1       RT @AbnInfVet: ...And Then Bloomberg Says He D...   \n",
       "2       RT @lgbtqnation: Federal judge considers separ...   \n",
       "3       RT @OKFosterWishes: URGENT; Beds needed to get...   \n",
       "4       RT @luke_brooks: N.America and EU! Our EP \"Wou...   \n",
       "...                                                   ...   \n",
       "248177  theawkwardmoment#theawkwardmoment when you sta...   \n",
       "248178  I will have the rest of the site updated when ...   \n",
       "248179  RT @EMANSANGELS: Follow @scottstorch and view ...   \n",
       "248180             Stupidity in numbers.  penn state riot   \n",
       "248181  RT @Srkrokx: Website Rank | Search Engine Opti...   \n",
       "\n",
       "                                             cleaned_text  isBot  \n",
       "0       __user_mention__ __user_mention__ YASS THANKS ...      0  \n",
       "1       RT __user_mention__ ...And Then Bloomberg Says...      0  \n",
       "2       RT __user_mention__ Federal judge considers se...      0  \n",
       "3       RT __user_mention__ URGENT; Beds needed to get...      0  \n",
       "4       RT __user_mention__ N.America and EU! Our EP \"...      0  \n",
       "...                                                   ...    ...  \n",
       "248177  theawkwardmoment#theawkwardmoment when you sta...      1  \n",
       "248178  I will have the rest of the site updated when ...      1  \n",
       "248179  RT __user_mention__ Follow __user_mention__ an...      1  \n",
       "248180              Stupidity in numbers. penn state riot      1  \n",
       "248181  RT __user_mention__ Website Rank | Search Engi...      1  \n",
       "\n",
       "[248182 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = df_tweets_all[[\"text\", \"cleaned_text\", \"bot\"]]\n",
    "df_tweets = df_tweets.rename(columns = {\"bot\": \"isBot\"})\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64a2fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>isBot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No surprises there. It's still happening today...</td>\n",
       "      <td>No surprises there. It's still happening today...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm in waiting room and everybody staring at m...</td>\n",
       "      <td>I'm in waiting room and everybody staring at m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @x_SupremeMee: Dead Serious . A Nigga Not F...</td>\n",
       "      <td>RT __user_mention__ Dead Serious . A Nigga Not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Am I not destroying my enemies when I make fri...</td>\n",
       "      <td>Am I not destroying my enemies when I make fri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @_christinareyes: today was such a good day...</td>\n",
       "      <td>RT __user_mention__ today was such a good day ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49631</th>\n",
       "      <td>2 people followed me in the last day thanks to...</td>\n",
       "      <td>2 people followed me in the last day thanks to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49632</th>\n",
       "      <td>@masonrudek congrats! We used to play Whitesbo...</td>\n",
       "      <td>__user_mention__ congrats! We used to play Whi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49633</th>\n",
       "      <td>RT @sirenmoonbee: @AmaiaOrmazabal @ArtywoodSla...</td>\n",
       "      <td>RT __user_mention__ __user_mention__ __user_me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49634</th>\n",
       "      <td>RT @NgaNgaDre: God is never too busy to answer...</td>\n",
       "      <td>RT __user_mention__ God is never too busy to a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49635</th>\n",
       "      <td>@Matty_Ice28 There's no way the Yankees eat mo...</td>\n",
       "      <td>__user_mention__ There's no way the Yankees ea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49636 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      No surprises there. It's still happening today...   \n",
       "1      I'm in waiting room and everybody staring at m...   \n",
       "2      RT @x_SupremeMee: Dead Serious . A Nigga Not F...   \n",
       "3      Am I not destroying my enemies when I make fri...   \n",
       "4      RT @_christinareyes: today was such a good day...   \n",
       "...                                                  ...   \n",
       "49631  2 people followed me in the last day thanks to...   \n",
       "49632  @masonrudek congrats! We used to play Whitesbo...   \n",
       "49633  RT @sirenmoonbee: @AmaiaOrmazabal @ArtywoodSla...   \n",
       "49634  RT @NgaNgaDre: God is never too busy to answer...   \n",
       "49635  @Matty_Ice28 There's no way the Yankees eat mo...   \n",
       "\n",
       "                                            cleaned_text  isBot  \n",
       "0      No surprises there. It's still happening today...      0  \n",
       "1      I'm in waiting room and everybody staring at m...      0  \n",
       "2      RT __user_mention__ Dead Serious . A Nigga Not...      0  \n",
       "3      Am I not destroying my enemies when I make fri...      1  \n",
       "4      RT __user_mention__ today was such a good day ...      0  \n",
       "...                                                  ...    ...  \n",
       "49631  2 people followed me in the last day thanks to...      0  \n",
       "49632  __user_mention__ congrats! We used to play Whi...      0  \n",
       "49633  RT __user_mention__ __user_mention__ __user_me...      0  \n",
       "49634  RT __user_mention__ God is never too busy to a...      0  \n",
       "49635  __user_mention__ There's no way the Yankees ea...      0  \n",
       "\n",
       "[49636 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = int(0.2 * len(df_tweets))\n",
    "df_tweets_searches = resample(df_tweets, replace = False, n_samples = n_samples, random_state = 101)\n",
    "df_tweets_searches = df_tweets_searches.reset_index(inplace = False, drop = True)\n",
    "df_tweets_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c3a04",
   "metadata": {},
   "source": [
    "# Model\n",
    "1. Logistic Regression (BoW)\n",
    "2. Random Forest Classifier (BoW)\n",
    "3. Logistic Regression (TF-IDF)\n",
    "4. Random Forest Classifier (TF-IDF)\n",
    "5. LSTM\n",
    "6. Logistic Regression (BERT)\n",
    "7. Random Forest Classifier (BERT)\n",
    "8. Adaboost Classifier (BERT)\n",
    "9. XGBoost (BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065976e0",
   "metadata": {},
   "source": [
    "## BERT Models (Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29709ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#initialising a pretrained bert model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", padding = True)\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "nlp = pipeline(\"feature-extraction\", tokenizer = tokenizer, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7883f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#store all the tweets after they have been encoded by BERT\n",
    "\n",
    "# feature_list = []\n",
    "\n",
    "# for index, row in df_tweets_searches.iterrows():\n",
    "#     #extracting the ith tweet and restricting the characters to 512, which is fine because twitter's limit is 280\n",
    "#     text = row['cleaned_text'][:512]\n",
    "#     #encoding all the individual words present in the tweet\n",
    "#     vec = np.array(nlp(text))\n",
    "#     #getting the mean representation of the words present in the tweet\n",
    "#     vec = vec.reshape((vec.shape[1], vec.shape[2])).mean(axis = 0)\n",
    "#     feature_list.append(vec)\n",
    "\n",
    "# feature_vectors_searches = np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea8f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors_searches = pd.read_csv(\"feature_vect_searches.csv\")\n",
    "feature_vectors_searches = feature_vectors_searches.drop(columns = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b977ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.395461</td>\n",
       "      <td>0.314507</td>\n",
       "      <td>0.362490</td>\n",
       "      <td>0.213974</td>\n",
       "      <td>0.333369</td>\n",
       "      <td>-0.068762</td>\n",
       "      <td>0.316718</td>\n",
       "      <td>-0.207122</td>\n",
       "      <td>-0.338681</td>\n",
       "      <td>-0.032407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140077</td>\n",
       "      <td>0.063303</td>\n",
       "      <td>-0.153159</td>\n",
       "      <td>-0.073506</td>\n",
       "      <td>-0.095945</td>\n",
       "      <td>0.121968</td>\n",
       "      <td>0.373144</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>0.037796</td>\n",
       "      <td>-0.182941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.170986</td>\n",
       "      <td>0.041638</td>\n",
       "      <td>0.140698</td>\n",
       "      <td>0.080176</td>\n",
       "      <td>0.374009</td>\n",
       "      <td>-0.405314</td>\n",
       "      <td>0.350578</td>\n",
       "      <td>0.124787</td>\n",
       "      <td>-0.046961</td>\n",
       "      <td>-0.294437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312045</td>\n",
       "      <td>0.146012</td>\n",
       "      <td>-0.363045</td>\n",
       "      <td>-0.148090</td>\n",
       "      <td>-0.066873</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.166132</td>\n",
       "      <td>0.207321</td>\n",
       "      <td>0.134877</td>\n",
       "      <td>-0.004206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132554</td>\n",
       "      <td>0.117530</td>\n",
       "      <td>0.106922</td>\n",
       "      <td>0.173113</td>\n",
       "      <td>-0.003577</td>\n",
       "      <td>-0.298844</td>\n",
       "      <td>0.077240</td>\n",
       "      <td>-0.041078</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-0.018072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176072</td>\n",
       "      <td>-0.032313</td>\n",
       "      <td>-0.135647</td>\n",
       "      <td>-0.070155</td>\n",
       "      <td>-0.281850</td>\n",
       "      <td>-0.359407</td>\n",
       "      <td>-0.040657</td>\n",
       "      <td>0.204591</td>\n",
       "      <td>-0.038190</td>\n",
       "      <td>0.070626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.134241</td>\n",
       "      <td>-0.084924</td>\n",
       "      <td>-0.033736</td>\n",
       "      <td>0.272944</td>\n",
       "      <td>0.246399</td>\n",
       "      <td>-0.238337</td>\n",
       "      <td>0.177381</td>\n",
       "      <td>0.031927</td>\n",
       "      <td>0.326889</td>\n",
       "      <td>-0.293079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300695</td>\n",
       "      <td>0.275399</td>\n",
       "      <td>-0.206875</td>\n",
       "      <td>-0.071240</td>\n",
       "      <td>0.496624</td>\n",
       "      <td>0.269286</td>\n",
       "      <td>-0.323785</td>\n",
       "      <td>0.088258</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>-0.190454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056847</td>\n",
       "      <td>0.283105</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>0.177009</td>\n",
       "      <td>0.168187</td>\n",
       "      <td>-0.330898</td>\n",
       "      <td>0.139501</td>\n",
       "      <td>-0.185742</td>\n",
       "      <td>-0.129203</td>\n",
       "      <td>-0.143451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029934</td>\n",
       "      <td>0.447064</td>\n",
       "      <td>-0.177487</td>\n",
       "      <td>-0.134292</td>\n",
       "      <td>-0.215164</td>\n",
       "      <td>-0.281553</td>\n",
       "      <td>-0.075762</td>\n",
       "      <td>0.044960</td>\n",
       "      <td>0.103758</td>\n",
       "      <td>0.579587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49631</th>\n",
       "      <td>0.411459</td>\n",
       "      <td>0.223123</td>\n",
       "      <td>-0.125041</td>\n",
       "      <td>-0.059729</td>\n",
       "      <td>0.252963</td>\n",
       "      <td>-0.074129</td>\n",
       "      <td>0.155126</td>\n",
       "      <td>-0.043803</td>\n",
       "      <td>-0.352230</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129086</td>\n",
       "      <td>-0.064744</td>\n",
       "      <td>-0.054788</td>\n",
       "      <td>-0.346518</td>\n",
       "      <td>-0.051776</td>\n",
       "      <td>0.288245</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-0.180260</td>\n",
       "      <td>-0.023279</td>\n",
       "      <td>0.192807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49632</th>\n",
       "      <td>0.131463</td>\n",
       "      <td>0.375077</td>\n",
       "      <td>-0.201440</td>\n",
       "      <td>0.118565</td>\n",
       "      <td>-0.016395</td>\n",
       "      <td>-0.155379</td>\n",
       "      <td>0.324532</td>\n",
       "      <td>-0.089360</td>\n",
       "      <td>-0.287430</td>\n",
       "      <td>-0.000772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123567</td>\n",
       "      <td>0.238414</td>\n",
       "      <td>-0.164729</td>\n",
       "      <td>-0.314040</td>\n",
       "      <td>-0.374253</td>\n",
       "      <td>-0.295125</td>\n",
       "      <td>-0.109618</td>\n",
       "      <td>0.354500</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.747328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49633</th>\n",
       "      <td>-0.039582</td>\n",
       "      <td>0.803484</td>\n",
       "      <td>-0.659892</td>\n",
       "      <td>0.127410</td>\n",
       "      <td>-0.208920</td>\n",
       "      <td>-0.011133</td>\n",
       "      <td>-0.068938</td>\n",
       "      <td>-0.277169</td>\n",
       "      <td>0.172432</td>\n",
       "      <td>-0.039849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289599</td>\n",
       "      <td>0.052794</td>\n",
       "      <td>-0.687014</td>\n",
       "      <td>-0.323827</td>\n",
       "      <td>-0.179736</td>\n",
       "      <td>-0.648473</td>\n",
       "      <td>-0.302837</td>\n",
       "      <td>-0.052786</td>\n",
       "      <td>0.379125</td>\n",
       "      <td>1.124434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49634</th>\n",
       "      <td>0.242117</td>\n",
       "      <td>0.199913</td>\n",
       "      <td>-0.092624</td>\n",
       "      <td>-0.042763</td>\n",
       "      <td>0.238782</td>\n",
       "      <td>-0.338223</td>\n",
       "      <td>0.171441</td>\n",
       "      <td>-0.148693</td>\n",
       "      <td>-0.117149</td>\n",
       "      <td>-0.057121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066954</td>\n",
       "      <td>0.280092</td>\n",
       "      <td>-0.107219</td>\n",
       "      <td>-0.149524</td>\n",
       "      <td>-0.042727</td>\n",
       "      <td>-0.337717</td>\n",
       "      <td>0.164451</td>\n",
       "      <td>0.209090</td>\n",
       "      <td>0.196218</td>\n",
       "      <td>0.371416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49635</th>\n",
       "      <td>0.181548</td>\n",
       "      <td>0.086993</td>\n",
       "      <td>-0.109630</td>\n",
       "      <td>-0.083998</td>\n",
       "      <td>-0.009981</td>\n",
       "      <td>-0.019615</td>\n",
       "      <td>0.290169</td>\n",
       "      <td>-0.014472</td>\n",
       "      <td>-0.199173</td>\n",
       "      <td>-0.162695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095575</td>\n",
       "      <td>0.104448</td>\n",
       "      <td>0.028072</td>\n",
       "      <td>-0.276218</td>\n",
       "      <td>-0.236278</td>\n",
       "      <td>-0.243900</td>\n",
       "      <td>-0.273079</td>\n",
       "      <td>0.178351</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.291532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49636 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.395461  0.314507  0.362490  0.213974  0.333369 -0.068762  0.316718   \n",
       "1      0.170986  0.041638  0.140698  0.080176  0.374009 -0.405314  0.350578   \n",
       "2      0.132554  0.117530  0.106922  0.173113 -0.003577 -0.298844  0.077240   \n",
       "3      0.134241 -0.084924 -0.033736  0.272944  0.246399 -0.238337  0.177381   \n",
       "4      0.056847  0.283105 -0.044481  0.177009  0.168187 -0.330898  0.139501   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49631  0.411459  0.223123 -0.125041 -0.059729  0.252963 -0.074129  0.155126   \n",
       "49632  0.131463  0.375077 -0.201440  0.118565 -0.016395 -0.155379  0.324532   \n",
       "49633 -0.039582  0.803484 -0.659892  0.127410 -0.208920 -0.011133 -0.068938   \n",
       "49634  0.242117  0.199913 -0.092624 -0.042763  0.238782 -0.338223  0.171441   \n",
       "49635  0.181548  0.086993 -0.109630 -0.083998 -0.009981 -0.019615  0.290169   \n",
       "\n",
       "              7         8         9  ...       758       759       760  \\\n",
       "0     -0.207122 -0.338681 -0.032407  ...  0.140077  0.063303 -0.153159   \n",
       "1      0.124787 -0.046961 -0.294437  ... -0.312045  0.146012 -0.363045   \n",
       "2     -0.041078  0.187893 -0.018072  ... -0.176072 -0.032313 -0.135647   \n",
       "3      0.031927  0.326889 -0.293079  ... -0.300695  0.275399 -0.206875   \n",
       "4     -0.185742 -0.129203 -0.143451  ...  0.029934  0.447064 -0.177487   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "49631 -0.043803 -0.352230  0.002781  ... -0.129086 -0.064744 -0.054788   \n",
       "49632 -0.089360 -0.287430 -0.000772  ... -0.123567  0.238414 -0.164729   \n",
       "49633 -0.277169  0.172432 -0.039849  ... -0.289599  0.052794 -0.687014   \n",
       "49634 -0.148693 -0.117149 -0.057121  ... -0.066954  0.280092 -0.107219   \n",
       "49635 -0.014472 -0.199173 -0.162695  ...  0.095575  0.104448  0.028072   \n",
       "\n",
       "            761       762       763       764       765       766       767  \n",
       "0     -0.073506 -0.095945  0.121968  0.373144  0.090164  0.037796 -0.182941  \n",
       "1     -0.148090 -0.066873  0.031754  0.166132  0.207321  0.134877 -0.004206  \n",
       "2     -0.070155 -0.281850 -0.359407 -0.040657  0.204591 -0.038190  0.070626  \n",
       "3     -0.071240  0.496624  0.269286 -0.323785  0.088258  0.093973 -0.190454  \n",
       "4     -0.134292 -0.215164 -0.281553 -0.075762  0.044960  0.103758  0.579587  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "49631 -0.346518 -0.051776  0.288245  0.222222 -0.180260 -0.023279  0.192807  \n",
       "49632 -0.314040 -0.374253 -0.295125 -0.109618  0.354500  0.005237  0.747328  \n",
       "49633 -0.323827 -0.179736 -0.648473 -0.302837 -0.052786  0.379125  1.124434  \n",
       "49634 -0.149524 -0.042727 -0.337717  0.164451  0.209090  0.196218  0.371416  \n",
       "49635 -0.276218 -0.236278 -0.243900 -0.273079  0.178351  0.066928  0.291532  \n",
       "\n",
       "[49636 rows x 768 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d95aff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_searches, x_test_searches, y_train_searches, y_test_searches = train_test_split(feature_vectors_searches, df_tweets_searches['isBot'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a47e6",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "We shall perform hyperparameter tuning for the models that use BERT features as the features. The method we will use to perform this tuning is Bayesian Optimisation, which is more efficient in finding the best hyperparameters as compared to Random Search and Grid Search as those 2 methods treat each trial of hyperparameters independently while Bayesian optimization is an informed search in the hyperparameter space in order to optimize the objective function.\n",
    "\n",
    "However, in the context of Random Forest, since most of the features are discrete, we used random search instead.\n",
    "\n",
    "Then, the tuned models will be tested on an independent test set and the best performing model will be selected based on this test set.\n",
    "\n",
    "(Note, the results are likely to be different each time the notebook is run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f487a",
   "metadata": {},
   "source": [
    "## 07 Random Forest Classifier (BERT)\n",
    "* Model (Random)\n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5624b0",
   "metadata": {},
   "source": [
    "### Model (Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33f514d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "rf_search = RandomForestClassifier()\n",
    "\n",
    "random_rf = {\"n_estimators\": [100, 200, 600, 800], \n",
    "             \"max_features\": [\"auto\", \"sqrt\", \"log2\"], \n",
    "             \"max_depth\": [10, 20, 40, 80], \n",
    "             \"min_samples_split\": [10, 40, 80, 100], \n",
    "             \"bootstrap\": [True, False]}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = rf_search,\n",
    "                                   param_distributions = random_rf,\n",
    "                                   scoring = 'f1',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = 5,\n",
    "                                   n_iter = 3,\n",
    "                                   random_state = 101,\n",
    "                                   verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc97e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "CPU times: total: 10min 50s\n",
      "Wall time: 59min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Execute search\n",
    "results_random_rf = random_search.fit(x_train_searches, np.ravel(y_train_searches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3a7d9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6642065703622988\n",
      "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 10, 'max_features': 'auto', 'max_depth': 80, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % results_random_rf.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_random_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae86e230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.41 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_prediction for the best model\n",
    "y_pred_rf_searches = results_random_rf.predict(x_test_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db598622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.822522159548751\n",
      "Log Loss: 6.129892574761366\n",
      "ROC AUC: 0.7611389197447823\n",
      "F1-score: 0.685581727337616\n",
      "Precision: 0.8602776533811016\n",
      "Recall: 0.5698605754968852\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88      6557\n",
      "           1       0.86      0.57      0.69      3371\n",
      "\n",
      "    accuracy                           0.82      9928\n",
      "   macro avg       0.84      0.76      0.78      9928\n",
      "weighted avg       0.83      0.82      0.81      9928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics for tuned random forest\n",
    "accuracy = metrics.accuracy_score(y_test_searches, y_pred_rf_searches)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_searches, y_pred_rf_searches)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_searches, y_pred_rf_searches)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_searches, y_pred_rf_searches)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_searches, y_pred_rf_searches)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_searches, y_pred_rf_searches)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_searches, y_pred_rf_searches)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b2b15",
   "metadata": {},
   "source": [
    "## 08 Adaboost Classifier (BERT)\n",
    "* Model (Random)\n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f8ee9",
   "metadata": {},
   "source": [
    "### Model (Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cd9a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_search = AdaBoostClassifier()\n",
    "\n",
    "random_adaboost = {\"n_estimators\": [50, 100, 200, 500, 800], \n",
    "                   \"learning_rate\": [0.1, 1.0, 1.1, 1.2]}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = adaboost_search,\n",
    "                                   param_distributions = random_adaboost,\n",
    "                                   scoring = 'f1',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = 5,\n",
    "                                   n_iter = 3,\n",
    "                                   random_state = 101,\n",
    "                                   verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae336a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "CPU times: total: 19min 54s\n",
      "Wall time: 1h 34min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results_random_adaboost = random_search.fit(x_train_searches, y_train_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50199170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.5871279432502629\n",
      "Best Hyperparameters: {'n_estimators': 200, 'learning_rate': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % results_random_adaboost.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_random_adaboost.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f727b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.41 s\n",
      "Wall time: 6.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_prediction for the best model\n",
    "y_pred_ada_searches = results_random_adaboost.predict(x_test_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f69786ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Log Loss: 8.634771094612367\n",
      "ROC AUC: 0.7007584766441483\n",
      "F1-score: 0.5978613091380428\n",
      "Precision: 0.658693323812924\n",
      "Recall: 0.5473153366953426\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      6557\n",
      "           1       0.66      0.55      0.60      3371\n",
      "\n",
      "    accuracy                           0.75      9928\n",
      "   macro avg       0.72      0.70      0.71      9928\n",
      "weighted avg       0.74      0.75      0.74      9928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_searches, y_pred_ada_searches)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_searches, y_pred_ada_searches)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_searches, y_pred_ada_searches)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_searches, y_pred_ada_searches)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_searches, y_pred_ada_searches)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_searches, y_pred_ada_searches)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_searches, y_pred_ada_searches)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234f5a9",
   "metadata": {},
   "source": [
    "## 09 XGBoost Classifier (BERT)\n",
    "* Model (Random)\n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d76a7",
   "metadata": {},
   "source": [
    "### Model (Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16a18385",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_train_searches = y_train_searches.value_counts()[0] / y_train_searches.value_counts()[1]\n",
    "\n",
    "xgb_search = XGBClassifier(scale_pos_weight = weight_train_searches,\n",
    "                           gamma = 0.1,\n",
    "                           alpha = 0.5,\n",
    "                           objective = \"binary:logistic\",\n",
    "                           eval_metric = \"logloss\")\n",
    "\n",
    "random_xgb = {\"max_depth\": [5, 10, 15, 20, 25], \n",
    "            \"subsample\": [0.6, 0.8, 1.0], \n",
    "            \"eta\": [0.01, 0.1, 0.5], \n",
    "            \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0]}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = xgb_search,\n",
    "                                   param_distributions = random_xgb,\n",
    "                                   scoring = 'f1',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = 5,\n",
    "                                   n_iter = 3,\n",
    "                                   random_state = 101,\n",
    "                                   verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "962e48b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "CPU times: total: 32min 38s\n",
      "Wall time: 1h 23min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results_random_xgb = random_search.fit(x_train_searches, y_train_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6edaeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.689243445497582\n",
      "Best Hyperparameters: {'subsample': 0.8, 'max_depth': 15, 'eta': 0.5, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % results_random_xgb.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_random_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e46641a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.16 s\n",
      "Wall time: 253 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_prediction for the best model\n",
    "y_pred_xgb_searches = results_random_xgb.predict(x_test_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f3a26de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8037872683319903\n",
      "Log Loss: 6.77701362687161\n",
      "ROC AUC: 0.7700899313131448\n",
      "F1-score: 0.6971393034825871\n",
      "Precision: 0.7324403789611238\n",
      "Recall: 0.6650845446455058\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.85      6557\n",
      "           1       0.73      0.67      0.70      3371\n",
      "\n",
      "    accuracy                           0.80      9928\n",
      "   macro avg       0.78      0.77      0.78      9928\n",
      "weighted avg       0.80      0.80      0.80      9928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d16bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing of necessary packages\n",
    "import nltk\n",
    "import re\n",
    "import emoji\n",
    "import demoji\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "from numpy import loadtxt, savetxt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D, BatchNormalization, Bidirectional\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#import bayes opt for hyperparameter tuning\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7325d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the dataset\n",
    "df_tweets = pd.read_csv('tweets_dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140a6921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>isBot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aleah is me</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__user_mention__ I got you bruh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__user_mention__ its a diet where u can only e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When we are no longer able to change a situati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__user_mention__ __user_mention__ __user_menti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>__user_mention__ jfc whats wrong with the foru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>__user_mention__ die hard with a vengeance __u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>What would you do.... IF! a little old man pic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>__user_mention__ lucky you..I can't unless if ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>RT __user_mention__ Shocker! See which cast me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cleaned_text  isBot\n",
       "0                                           aleah is me       0\n",
       "1                        __user_mention__ I got you bruh      0\n",
       "2      __user_mention__ its a diet where u can only e...      1\n",
       "3      When we are no longer able to change a situati...      1\n",
       "4      __user_mention__ __user_mention__ __user_menti...      0\n",
       "...                                                  ...    ...\n",
       "49995  __user_mention__ jfc whats wrong with the foru...      0\n",
       "49996  __user_mention__ die hard with a vengeance __u...      0\n",
       "49997  What would you do.... IF! a little old man pic...      1\n",
       "49998  __user_mention__ lucky you..I can't unless if ...      1\n",
       "49999  RT __user_mention__ Shocker! See which cast me...      0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = df_tweets[[\"cleaned_text\", \"isBot\"]]\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64a2fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>isBot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__user_mention__ I'm up at 6am every day.. It sux</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attitude stinks, but what point do i have to p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__user_mention__ god, I've got to agree with a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__user_mention__ I understand though. For a fe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Damn Laura STILL in there eatin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>__user_mention__ you already know... I'm VIP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>The Week in Pictures: June 21 - 28  via __user...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>Education Advisors Will Help You: Find a degre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>RT __user_mention__ “@blackswan305: Who WOULDN...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>Thumb Through That Check !!!!!!!!!!!!!!!!!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cleaned_text  isBot\n",
       "0      __user_mention__ I'm up at 6am every day.. It sux      0\n",
       "1      Attitude stinks, but what point do i have to p...      1\n",
       "2      __user_mention__ god, I've got to agree with a...      1\n",
       "3      __user_mention__ I understand though. For a fe...      0\n",
       "4                        Damn Laura STILL in there eatin      0\n",
       "...                                                  ...    ...\n",
       "12495       __user_mention__ you already know... I'm VIP      0\n",
       "12496  The Week in Pictures: June 21 - 28  via __user...      1\n",
       "12497  Education Advisors Will Help You: Find a degre...      1\n",
       "12498  RT __user_mention__ “@blackswan305: Who WOULDN...      1\n",
       "12499       Thumb Through That Check !!!!!!!!!!!!!!!!!!!      1\n",
       "\n",
       "[12500 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = int(0.25 * len(df_tweets))\n",
    "df_tweets_searches = resample(df_tweets, replace = False, n_samples = n_samples, random_state = 101)\n",
    "df_tweets_searches = df_tweets_searches.reset_index(inplace = False, drop = True)\n",
    "df_tweets_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c3a04",
   "metadata": {},
   "source": [
    "# Model\n",
    "1. Logistic Regression (BoW)\n",
    "2. Random Forest Classifier (BoW)\n",
    "3. Logistic Regression (TF-IDF)\n",
    "4. Random Forest Classifier (TF-IDF)\n",
    "5. LSTM\n",
    "6. Logistic Regression (BERT)\n",
    "7. Random Forest Classifier (BERT)\n",
    "8. Adaboost Classifier (BERT)\n",
    "9. XGBoost (BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065976e0",
   "metadata": {},
   "source": [
    "## BERT Models (Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29709ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#initialising a pretrained bert model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", padding = True)\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "nlp = pipeline(\"feature-extraction\", tokenizer = tokenizer, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7883f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#store all the tweets after they have been encoded by BERT\n",
    "\n",
    "# feature_list = []\n",
    "\n",
    "# for index, row in df_tweets_searches.iterrows():\n",
    "#     #extracting the ith tweet and restricting the characters to 512, which is fine because twitter's limit is 280\n",
    "#     text = row['cleaned_text'][:512]\n",
    "#     #encoding all the individual words present in the tweet\n",
    "#     vec = np.array(nlp(text))\n",
    "#     #getting the mean representation of the words present in the tweet\n",
    "#     vec = vec.reshape((vec.shape[1], vec.shape[2])).mean(axis = 0)\n",
    "#     feature_list.append(vec)\n",
    "\n",
    "# feature_vectors_searches = np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea8f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors_searches = pd.read_csv(\"feature_vect_searches.csv\")\n",
    "feature_vectors_searches = feature_vectors_searches.drop(columns = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8317b6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277880</td>\n",
       "      <td>0.262478</td>\n",
       "      <td>0.010301</td>\n",
       "      <td>0.044697</td>\n",
       "      <td>0.332548</td>\n",
       "      <td>-0.044443</td>\n",
       "      <td>0.153921</td>\n",
       "      <td>-0.158961</td>\n",
       "      <td>-0.002900</td>\n",
       "      <td>-0.049170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090998</td>\n",
       "      <td>0.140967</td>\n",
       "      <td>-0.202905</td>\n",
       "      <td>-0.195144</td>\n",
       "      <td>-0.004835</td>\n",
       "      <td>-0.132333</td>\n",
       "      <td>-0.120175</td>\n",
       "      <td>0.038537</td>\n",
       "      <td>-0.031248</td>\n",
       "      <td>0.512940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.205477</td>\n",
       "      <td>0.086723</td>\n",
       "      <td>0.100212</td>\n",
       "      <td>-0.188577</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>0.258901</td>\n",
       "      <td>0.285367</td>\n",
       "      <td>0.140156</td>\n",
       "      <td>-0.053721</td>\n",
       "      <td>-0.054970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222869</td>\n",
       "      <td>-0.253721</td>\n",
       "      <td>-0.164111</td>\n",
       "      <td>0.022392</td>\n",
       "      <td>-0.381319</td>\n",
       "      <td>-0.180698</td>\n",
       "      <td>-0.026798</td>\n",
       "      <td>0.693803</td>\n",
       "      <td>0.317107</td>\n",
       "      <td>0.157766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.299577</td>\n",
       "      <td>0.499393</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.159204</td>\n",
       "      <td>0.239811</td>\n",
       "      <td>-0.370334</td>\n",
       "      <td>0.107382</td>\n",
       "      <td>-0.068318</td>\n",
       "      <td>0.180709</td>\n",
       "      <td>-0.256709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065183</td>\n",
       "      <td>0.190202</td>\n",
       "      <td>-0.246934</td>\n",
       "      <td>-0.301988</td>\n",
       "      <td>-0.012573</td>\n",
       "      <td>-0.287234</td>\n",
       "      <td>0.196079</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.059463</td>\n",
       "      <td>0.324868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.310165</td>\n",
       "      <td>0.162723</td>\n",
       "      <td>-0.039514</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.255538</td>\n",
       "      <td>-0.264964</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>0.105345</td>\n",
       "      <td>-0.017594</td>\n",
       "      <td>0.053867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111539</td>\n",
       "      <td>0.112330</td>\n",
       "      <td>-0.181848</td>\n",
       "      <td>-0.073778</td>\n",
       "      <td>-0.059616</td>\n",
       "      <td>0.045054</td>\n",
       "      <td>0.191947</td>\n",
       "      <td>0.286819</td>\n",
       "      <td>-0.067321</td>\n",
       "      <td>0.163990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.167977</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>0.249408</td>\n",
       "      <td>0.063067</td>\n",
       "      <td>-0.408302</td>\n",
       "      <td>0.304360</td>\n",
       "      <td>0.120799</td>\n",
       "      <td>0.175538</td>\n",
       "      <td>-0.130975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064510</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>-0.092907</td>\n",
       "      <td>-0.162694</td>\n",
       "      <td>-0.093241</td>\n",
       "      <td>0.073792</td>\n",
       "      <td>-0.128327</td>\n",
       "      <td>0.185978</td>\n",
       "      <td>0.177096</td>\n",
       "      <td>-0.108767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>0.330300</td>\n",
       "      <td>0.295764</td>\n",
       "      <td>0.117434</td>\n",
       "      <td>-0.133158</td>\n",
       "      <td>0.259933</td>\n",
       "      <td>-0.036908</td>\n",
       "      <td>0.353735</td>\n",
       "      <td>-0.075970</td>\n",
       "      <td>-0.075929</td>\n",
       "      <td>-0.182939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120197</td>\n",
       "      <td>-0.097423</td>\n",
       "      <td>-0.254647</td>\n",
       "      <td>-0.171841</td>\n",
       "      <td>-0.397316</td>\n",
       "      <td>-0.315863</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.099914</td>\n",
       "      <td>0.159043</td>\n",
       "      <td>0.309869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>0.135886</td>\n",
       "      <td>0.188740</td>\n",
       "      <td>-0.247926</td>\n",
       "      <td>0.151798</td>\n",
       "      <td>-0.042878</td>\n",
       "      <td>-0.070221</td>\n",
       "      <td>0.372331</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>0.053845</td>\n",
       "      <td>-0.200384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179420</td>\n",
       "      <td>0.138549</td>\n",
       "      <td>-0.259815</td>\n",
       "      <td>-0.162573</td>\n",
       "      <td>-0.340535</td>\n",
       "      <td>-0.471309</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.156366</td>\n",
       "      <td>0.287940</td>\n",
       "      <td>0.295685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>0.156243</td>\n",
       "      <td>-0.004264</td>\n",
       "      <td>-0.043666</td>\n",
       "      <td>0.077168</td>\n",
       "      <td>-0.081637</td>\n",
       "      <td>0.376960</td>\n",
       "      <td>0.178357</td>\n",
       "      <td>0.198301</td>\n",
       "      <td>-0.329599</td>\n",
       "      <td>0.116169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012415</td>\n",
       "      <td>-0.176164</td>\n",
       "      <td>-0.050735</td>\n",
       "      <td>-0.229026</td>\n",
       "      <td>0.031625</td>\n",
       "      <td>-0.123867</td>\n",
       "      <td>0.405285</td>\n",
       "      <td>-0.052769</td>\n",
       "      <td>0.278198</td>\n",
       "      <td>0.177824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>0.095616</td>\n",
       "      <td>0.404711</td>\n",
       "      <td>-0.304204</td>\n",
       "      <td>0.147562</td>\n",
       "      <td>-0.119110</td>\n",
       "      <td>-0.189288</td>\n",
       "      <td>0.179682</td>\n",
       "      <td>-0.116130</td>\n",
       "      <td>0.041789</td>\n",
       "      <td>0.049917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275982</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>-0.267629</td>\n",
       "      <td>-0.287303</td>\n",
       "      <td>-0.189357</td>\n",
       "      <td>-0.462369</td>\n",
       "      <td>-0.034423</td>\n",
       "      <td>0.313417</td>\n",
       "      <td>0.192184</td>\n",
       "      <td>0.465953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>0.034480</td>\n",
       "      <td>0.820358</td>\n",
       "      <td>0.449930</td>\n",
       "      <td>0.571896</td>\n",
       "      <td>-0.323949</td>\n",
       "      <td>-0.421478</td>\n",
       "      <td>0.182963</td>\n",
       "      <td>0.388028</td>\n",
       "      <td>-0.034713</td>\n",
       "      <td>0.406962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389312</td>\n",
       "      <td>0.009301</td>\n",
       "      <td>-0.328821</td>\n",
       "      <td>-0.428290</td>\n",
       "      <td>-0.345214</td>\n",
       "      <td>-0.563371</td>\n",
       "      <td>0.412790</td>\n",
       "      <td>0.847565</td>\n",
       "      <td>0.745926</td>\n",
       "      <td>-0.014394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.277880  0.262478  0.010301  0.044697  0.332548 -0.044443  0.153921   \n",
       "1      0.205477  0.086723  0.100212 -0.188577  0.081971  0.258901  0.285367   \n",
       "2      0.299577  0.499393  0.003503  0.159204  0.239811 -0.370334  0.107382   \n",
       "3      0.310165  0.162723 -0.039514  0.008919  0.255538 -0.264964  0.289035   \n",
       "4      0.167977  0.022978  0.033517  0.249408  0.063067 -0.408302  0.304360   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "12495  0.330300  0.295764  0.117434 -0.133158  0.259933 -0.036908  0.353735   \n",
       "12496  0.135886  0.188740 -0.247926  0.151798 -0.042878 -0.070221  0.372331   \n",
       "12497  0.156243 -0.004264 -0.043666  0.077168 -0.081637  0.376960  0.178357   \n",
       "12498  0.095616  0.404711 -0.304204  0.147562 -0.119110 -0.189288  0.179682   \n",
       "12499  0.034480  0.820358  0.449930  0.571896 -0.323949 -0.421478  0.182963   \n",
       "\n",
       "              7         8         9  ...       758       759       760  \\\n",
       "0     -0.158961 -0.002900 -0.049170  ... -0.090998  0.140967 -0.202905   \n",
       "1      0.140156 -0.053721 -0.054970  ... -0.222869 -0.253721 -0.164111   \n",
       "2     -0.068318  0.180709 -0.256709  ... -0.065183  0.190202 -0.246934   \n",
       "3      0.105345 -0.017594  0.053867  ... -0.111539  0.112330 -0.181848   \n",
       "4      0.120799  0.175538 -0.130975  ... -0.064510  0.084802 -0.092907   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "12495 -0.075970 -0.075929 -0.182939  ... -0.120197 -0.097423 -0.254647   \n",
       "12496 -0.003703  0.053845 -0.200384  ... -0.179420  0.138549 -0.259815   \n",
       "12497  0.198301 -0.329599  0.116169  ...  0.012415 -0.176164 -0.050735   \n",
       "12498 -0.116130  0.041789  0.049917  ... -0.275982  0.024390 -0.267629   \n",
       "12499  0.388028 -0.034713  0.406962  ...  0.389312  0.009301 -0.328821   \n",
       "\n",
       "            761       762       763       764       765       766       767  \n",
       "0     -0.195144 -0.004835 -0.132333 -0.120175  0.038537 -0.031248  0.512940  \n",
       "1      0.022392 -0.381319 -0.180698 -0.026798  0.693803  0.317107  0.157766  \n",
       "2     -0.301988 -0.012573 -0.287234  0.196079  0.040103  0.059463  0.324868  \n",
       "3     -0.073778 -0.059616  0.045054  0.191947  0.286819 -0.067321  0.163990  \n",
       "4     -0.162694 -0.093241  0.073792 -0.128327  0.185978  0.177096 -0.108767  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "12495 -0.171841 -0.397316 -0.315863  0.028011  0.099914  0.159043  0.309869  \n",
       "12496 -0.162573 -0.340535 -0.471309  0.074000  0.156366  0.287940  0.295685  \n",
       "12497 -0.229026  0.031625 -0.123867  0.405285 -0.052769  0.278198  0.177824  \n",
       "12498 -0.287303 -0.189357 -0.462369 -0.034423  0.313417  0.192184  0.465953  \n",
       "12499 -0.428290 -0.345214 -0.563371  0.412790  0.847565  0.745926 -0.014394  \n",
       "\n",
       "[12500 rows x 768 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d95aff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_searches, x_test_searches, y_train_searches, y_test_searches = train_test_split(feature_vectors_searches, df_tweets_searches['isBot'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a47e6",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "We shall perform hyperparameter tuning for the models that use BERT features as the features. The method we will use to perform this tuning is Bayesian Optimisation, which is more efficient in finding the best hyperparameters as compared to Random Search and Grid Search as those 2 methods treat each trial of hyperparameters independently while Bayesian optimization is an informed search in the hyperparameter space in order to optimize the objective function.\n",
    "\n",
    "However, in the context of Random Forest, since most of the features are discrete, we used random search instead.\n",
    "\n",
    "Then, the tuned models will be tested on an independent test set and the best performing model will be selected based on this test set.\n",
    "\n",
    "(Note, the results are likely to be different each time the notebook is run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f487a",
   "metadata": {},
   "source": [
    "## 07 Random Forest Classifier (BERT)\n",
    "* Model (Random)\n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5624b0",
   "metadata": {},
   "source": [
    "### Model (Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f514d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "rf_search = RandomForestClassifier()\n",
    "\n",
    "random_rf = {\"n_estimators\": [100, 200, 600, 800], \n",
    "             \"max_features\": [\"auto\", \"sqrt\", \"log2\"], \n",
    "             \"max_depth\": [10, 20, 40, 80], \n",
    "             \"min_samples_split\": [10, 40, 80, 100], \n",
    "             \"bootstrap\": [True, False]}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = rf_search,\n",
    "                                   param_distributions = random_rf,\n",
    "                                   scoring = 'f1',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = 5,\n",
    "                                   n_iter = 3,\n",
    "                                   random_state = 101,\n",
    "                                   verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc97e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "CPU times: total: 1min 51s\n",
      "Wall time: 9min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Execute search\n",
    "results_random_rf = random_search.fit(x_train_searches, np.ravel(y_train_searches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a7d9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7545117473905061\n",
      "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 10, 'max_features': 'auto', 'max_depth': 80, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % results_random_rf.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_random_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae86e230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 328 ms\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_prediction for the best model\n",
    "y_pred_rf_searches = results_random_rf.predict(x_test_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db598622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.746\n",
      "Log Loss: 8.77296722488801\n",
      "ROC AUC: 0.7454309314038012\n",
      "F1-score: 0.759013282732448\n",
      "Precision: 0.7304601899196493\n",
      "Recall: 0.7898894154818326\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73      1234\n",
      "           1       0.73      0.79      0.76      1266\n",
      "\n",
      "    accuracy                           0.75      2500\n",
      "   macro avg       0.75      0.75      0.75      2500\n",
      "weighted avg       0.75      0.75      0.75      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics for tuned random forest\n",
    "accuracy = metrics.accuracy_score(y_test_searches, y_pred_rf_searches)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_searches, y_pred_rf_searches)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_searches, y_pred_rf_searches)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_searches, y_pred_rf_searches)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_searches, y_pred_rf_searches)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_searches, y_pred_rf_searches)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_searches, y_pred_rf_searches)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b2b15",
   "metadata": {},
   "source": [
    "## 08 Adaboost Classifier (BERT)\n",
    "* Model (Random)\n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f8ee9",
   "metadata": {},
   "source": [
    "### Model (Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cd9a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_search = AdaBoostClassifier()\n",
    "\n",
    "random_adaboost = {\"n_estimators\": [50, 100, 200, 500, 800], \n",
    "                   \"learning_rate\": [0.1, 1.0, 1.1, 1.2]}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = adaboost_search,\n",
    "                                   param_distributions = random_adaboost,\n",
    "                                   scoring = 'f1',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = 5,\n",
    "                                   n_iter = 3,\n",
    "                                   random_state = 101,\n",
    "                                   verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ae336a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "CPU times: total: 12min 18s\n",
      "Wall time: 29min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results_random_adaboost = random_search.fit(x_train_searches, y_train_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50199170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7271169467058299\n",
      "Best Hyperparameters: {'n_estimators': 500, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % results_random_adaboost.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_random_adaboost.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f727b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.8 s\n",
      "Wall time: 4.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_prediction for the best model\n",
    "y_pred_ada_searches = results_random_adaboost.predict(x_test_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f69786ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7264\n",
      "Log Loss: 9.449926602550315\n",
      "ROC AUC: 0.7260991240804894\n",
      "F1-score: 0.7350890782339271\n",
      "Precision: 0.7211246200607903\n",
      "Recall: 0.7496050552922591\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.72      1234\n",
      "           1       0.72      0.75      0.74      1266\n",
      "\n",
      "    accuracy                           0.73      2500\n",
      "   macro avg       0.73      0.73      0.73      2500\n",
      "weighted avg       0.73      0.73      0.73      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_searches, y_pred_ada_searches)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_searches, y_pred_ada_searches)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_searches, y_pred_ada_searches)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_searches, y_pred_ada_searches)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_searches, y_pred_ada_searches)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_searches, y_pred_ada_searches)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_searches, y_pred_ada_searches)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234f5a9",
   "metadata": {},
   "source": [
    "## 9 XGBoost Classifier (BERT)\n",
    "* Model (Random)\n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d76a7",
   "metadata": {},
   "source": [
    "### Model (Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16a18385",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_train_searches = y_train_searches.value_counts()[0] / y_train_searches.value_counts()[1]\n",
    "\n",
    "xgb_search = XGBClassifier(scale_pos_weight = weight_train_searches,\n",
    "                           gamma = 0.1,\n",
    "                           alpha = 0.5,\n",
    "                           objective = \"binary:logistic\",\n",
    "                           eval_metric = \"logloss\")\n",
    "\n",
    "random_xgb = {\"max_depth\": [5, 10, 15, 20, 25], \n",
    "            \"subsample\": [0.6, 0.8, 1.0], \n",
    "            \"eta\": [0.01, 0.1, 0.5], \n",
    "            \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0]}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = xgb_search,\n",
    "                                   param_distributions = random_xgb,\n",
    "                                   scoring = 'f1',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = 5,\n",
    "                                   n_iter = 3,\n",
    "                                   random_state = 101,\n",
    "                                   verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "962e48b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "CPU times: total: 14min 4s\n",
      "Wall time: 18min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results_random_xgb = random_search.fit(x_train_searches, y_train_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6edaeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7428479366373191\n",
      "Best Hyperparameters: {'subsample': 0.8, 'max_depth': 25, 'eta': 0.01, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % results_random_xgb.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_random_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e46641a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 469 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_prediction for the best model\n",
    "y_pred_xgb_searches = results_random_xgb.predict(x_test_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f3a26de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n",
      "Log Loss: 8.98020404116411\n",
      "ROC AUC: 0.7393736189737327\n",
      "F1-score: 0.7543461829176114\n",
      "Precision: 0.7231884057971014\n",
      "Recall: 0.7883096366508688\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72      1234\n",
      "           1       0.72      0.79      0.75      1266\n",
      "\n",
      "    accuracy                           0.74      2500\n",
      "   macro avg       0.74      0.74      0.74      2500\n",
      "weighted avg       0.74      0.74      0.74      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_searches, y_pred_xgb_searches)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

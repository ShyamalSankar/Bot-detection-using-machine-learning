{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d16bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing of necessary packages\n",
    "import nltk\n",
    "import re\n",
    "import emoji\n",
    "import demoji\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from numpy import loadtxt, savetxt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D, BatchNormalization, Bidirectional\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7325d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the dataset\n",
    "df_tweets = pd.read_csv('tweets_dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140a6921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>isBot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aleah is me</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__user_mention__ I got you bruh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__user_mention__ its a diet where u can only e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When we are no longer able to change a situati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__user_mention__ __user_mention__ __user_menti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>__user_mention__ jfc whats wrong with the foru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>__user_mention__ die hard with a vengeance __u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>What would you do.... IF! a little old man pic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>__user_mention__ lucky you..I can't unless if ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>RT __user_mention__ Shocker! See which cast me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cleaned_text  isBot\n",
       "0                                           aleah is me       0\n",
       "1                        __user_mention__ I got you bruh      0\n",
       "2      __user_mention__ its a diet where u can only e...      1\n",
       "3      When we are no longer able to change a situati...      1\n",
       "4      __user_mention__ __user_mention__ __user_menti...      0\n",
       "...                                                  ...    ...\n",
       "49995  __user_mention__ jfc whats wrong with the foru...      0\n",
       "49996  __user_mention__ die hard with a vengeance __u...      0\n",
       "49997  What would you do.... IF! a little old man pic...      1\n",
       "49998  __user_mention__ lucky you..I can't unless if ...      1\n",
       "49999  RT __user_mention__ Shocker! See which cast me...      0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = df_tweets[[\"cleaned_text\", \"isBot\"]]\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c3a04",
   "metadata": {},
   "source": [
    "# Model\n",
    "1. Logistic Regression (BoW)\n",
    "2. Random Forest Classifier (BoW)\n",
    "3. Logistic Regression (TF-IDF)\n",
    "4. Random Forest Classifier (TF-IDF)\n",
    "5. LSTM\n",
    "6. Logistic Regression (BERT)\n",
    "7. Random Forest Classifier (BERT)\n",
    "8. Adaboost Classifier (BERT)\n",
    "9. XGBoost (BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065976e0",
   "metadata": {},
   "source": [
    "## BERT Models\n",
    "While previously the word embeddings from Glove are not fully context dependent, let us consider an embedding that considers both context and both directions, ie the BERT word embedding\n",
    "\n",
    "Here, first, we generate the BERT feature vector for each tweet and then we train models on those feature representations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29709ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#initialising a pretrained bert model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", padding = True)\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "nlp = pipeline(\"feature-extraction\", tokenizer = tokenizer, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7883f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#store all the tweets after they have been encoded by BERT\n",
    "\n",
    "# feature_list = []\n",
    "\n",
    "# for index, row in df_tweets.iterrows():\n",
    "#     #extracting the ith tweet and restricting the characters to 512, which is fine because twitter's limit is 280\n",
    "#     text = row['cleaned_text'][:512]\n",
    "#     #encoding all the individual words present in the tweet\n",
    "#     vec = np.array(nlp(text))\n",
    "#     #getting the mean representation of the words present in the tweet\n",
    "#     vec = vec.reshape((vec.shape[1], vec.shape[2])).mean(axis = 0)\n",
    "#     feature_list.append(vec)\n",
    "\n",
    "# feature_vectors = np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a604f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = pd.read_csv(\"feature_vect.csv\")\n",
    "feature_vectors = feature_vectors.drop(columns = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0b0d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the generated features into training and testing features\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature_vectors, df_tweets['isBot'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d5da4",
   "metadata": {},
   "source": [
    "## 06 Logistic Regression (BERT)\n",
    "* Model\n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbd6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "log_regression = LogisticRegression(max_iter = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0016d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit Model\n",
    "log_model = log_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0304a59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_prediction\n",
    "y_pred = log_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5cb592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7351\n",
      "Log Loss: 9.149428453349286\n",
      "ROC AUC: 0.7350831729810059\n",
      "F1-score: 0.7323972118395797\n",
      "Precision: 0.7311415893505446\n",
      "Recall: 0.7336571544221817\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      5059\n",
      "           1       0.73      0.73      0.73      4941\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.74     10000\n",
      "weighted avg       0.74      0.74      0.74     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f487a",
   "metadata": {},
   "source": [
    "## 07 Random Forest Classifier (BERT)\n",
    "* Model\n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413654fe",
   "metadata": {},
   "source": [
    "### Model (Optimal Hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1354b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (initialise the object based on parameters selected by random search)\n",
    "rf_classifier = RandomForestClassifier(bootstrap = False, \n",
    "                                       max_depth = 80, \n",
    "                                       max_features = \"auto\", \n",
    "                                       min_samples_split = 10, \n",
    "                                       n_estimators = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b9af20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit Model\n",
    "rf_model = rf_classifier.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "052f492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_prediction for the best model\n",
    "y_pred_optimal_rf = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd4dccc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.801\n",
      "Log Loss: 6.873295902612044\n",
      "ROC AUC: 0.8009675667239906\n",
      "F1-score: 0.798542215023284\n",
      "Precision: 0.7988657079197894\n",
      "Recall: 0.7982189840113337\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      5059\n",
      "           1       0.80      0.80      0.80      4941\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics for tuned random forest\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_optimal_rf)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_optimal_rf)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_optimal_rf)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_optimal_rf)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_optimal_rf)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_optimal_rf)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred_optimal_rf)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b2b15",
   "metadata": {},
   "source": [
    "## 08 Adaboost Classifier (BERT)\n",
    "* Model\n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681997df",
   "metadata": {},
   "source": [
    "### Model (Optimal Hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04c2dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (initialise the object based on parameters selected by random search)\n",
    "adaboost_classifier = AdaBoostClassifier(n_estimators = 500, \n",
    "                                         learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebef495a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit Model\n",
    "adaboost_model = adaboost_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba3ed5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_prediction for the best model\n",
    "y_pred_optimal_ada = adaboost_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f761e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7156\n",
      "Log Loss: 9.822949945320703\n",
      "ROC AUC: 0.7158035084805209\n",
      "F1-score: 0.718080888183981\n",
      "Precision: 0.7037108995531377\n",
      "Recall: 0.733049989880591\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71      5059\n",
      "           1       0.70      0.73      0.72      4941\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.72      0.72     10000\n",
      "weighted avg       0.72      0.72      0.72     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_optimal_ada)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_optimal_ada)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_optimal_ada)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_optimal_ada)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_optimal_ada)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_optimal_ada)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred_optimal_ada)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234f5a9",
   "metadata": {},
   "source": [
    "## 09 XGBoost Classifier (BERT)\n",
    "* Model\n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464397c6",
   "metadata": {},
   "source": [
    "### Model (Optimal Hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1ce1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (initialise the object based on parameters selected by bayesian optimisation)\n",
    "weight_train = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "\n",
    "xgb_classifier = XGBClassifier(gamma = 0.1,\n",
    "                               alpha = 0.5,\n",
    "                               max_depth = 25, \n",
    "                               eta = 0.01, \n",
    "                               subsample = 0.8,\n",
    "                               colsample_bytree = 1.0,\n",
    "                               scale_pos_weight = weight_train,\n",
    "                               objective = \"binary:logistic\",\n",
    "                               eval_metric = \"logloss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc00a4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit Model\n",
    "xgb_model = xgb_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6db60a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_prediction for the best model\n",
    "y_pred_optimal_xgb = xgb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df7edc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7883\n",
      "Log Loss: 7.311953235339612\n",
      "ROC AUC: 0.7885549383896214\n",
      "F1-score: 0.7908722710658896\n",
      "Precision: 0.772481667309919\n",
      "Recall: 0.810159886662619\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79      5059\n",
      "           1       0.77      0.81      0.79      4941\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_optimal_xgb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_optimal_xgb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_optimal_xgb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_optimal_xgb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_optimal_xgb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_optimal_xgb)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred_optimal_xgb)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
